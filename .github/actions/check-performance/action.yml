name: Check performance
author: gerardo.dominguez.aldama@intel.com
description: |
  This action compares the result of a workload test with a specified threshold
  and writes a GITHUB_SUMMARY to show if the workload has an accepted tolerance.

inputs:
  output_folder:
    description: Output folder were test results were saved.
    required: true
    default: ${GITHUB_WORKSPACE}/tests/cicd/output
  workload:
    description: Workload test.
    required: true
    default: resnet50v1.5-inference
  framework:
    description: Framework used on the workload.
    required: true
    default: tensorflow
  script:
    description: Script being executed by the workload.
    required: true
    default: inference_realtime_multi_instance.sh
  benchmark_type:
    description: Type of result to compare, eg. latency, throughput, accuracy, etc.
    required: true
    default: throughput
  precisions:
    description: List of precisions to analyze.
    required: true
    default: "['int8','fp32','bfloat16','bfloat32']"
  thresholds:
    description: List of thresholds to compare the results.
    required: true
    default: "['650','625','600','575']"
  tolerance:
    description: Specifies the accepted range where the result can exist.
    required: true
    default: 0.05
  token:
    description: "GITHUB_TOKEN or a repo scoped PAT."
    required: true

runs:
  using: "composite"
  steps:
    - name: Install dependencies
      shell: bash
      run: |
        apt-get update
        apt-get install jq -y
        pip install pandas tabulate
    - name: Check performance
      shell: bash
      run: |
        mkdir -p ${{ inputs.output_folder }}/performances
        IFS=',()][' read -a PRECISIONS <<< ${{ inputs.precisions }}
        IFS=',()][' read -a THRESHOLDS <<< ${{ inputs.thresholds }}
        NUM_THRESHOLDS=${#THRESHOLDS[@]}
        for idx in $(seq 0 $NUM_THRESHOLDS); do
          if [ "${THRESHOLDS[idx]}" != '' ]; then
            LOWER_LIMIT=$(echo "${THRESHOLDS[idx]}*(1-${{ inputs.tolerance }})" | bc -l)
            UPPER_LIMIT=$(echo "${THRESHOLDS[idx]}*(1+${{ inputs.tolerance }})" | bc -l)
            cd ${{ inputs.output_folder }}/${{ env.FOLDER }}/${{ inputs.workload }}/${{ inputs.script }}/${PRECISIONS[idx]}
            OUTPUT_FILES=(*)
            NUM_OUTPUT_FILES=${#OUTPUT_FILES[@]}
            for idy in $(seq 0 $NUM_OUTPUT_FILES); do
              RESULT=$(grep -i ${{ inputs.benchmark_type }} ${OUTPUT_FILES[idy]} | grep -Eo '[0-9]+\.[0-9]+{1,4}' | tail -n 1) || echo "Benchmark not found on file ${idy}"
              if [[ ! -z "${RESULT}" ]]; then
                break
              fi
            done
            if [[ "${{ inputs.benchmark_type }}" == "accuracy" ]] && (( $(echo "${RESULT} > 1" | bc -l) )); then
              RESULT=$(grep -i ${{ inputs.benchmark_type }} ${OUTPUT_FILES[idy]} | grep -Eo '[0-9]+\.[0-9]+{1,4}' | tail -n 2 | head -1)
              if (( $(echo "${RESULT} > 1" | bc -l) )); then
                RESULT=0
              fi
            fi

            JOB_URL=$(curl -L -s -H 'Accept: application/vnd.github+json' -H "Authorization: Bearer ${{ inputs.token }}" \
              https://api.github.com/repos/${{ github.repository }}/actions/runs/${{ github.run_id }}/jobs |  jq '.jobs[] | \
              select(.name | contains("${{ inputs.framework }}")) | select(.name | contains("${{ inputs.workload }}")) | \
              select(.name | contains("${{ inputs.script }}")) | .html_url' | sed 's/"//g')
            STEP_URL=${JOB_URL}#step:9:1

            if [[ "${{ inputs.benchmark_type }}" == "latency" ]] && (( $(echo "${RESULT} < ${UPPER_LIMIT}" | bc -l) )); then
              python ${GITHUB_WORKSPACE}/.github/actions/check-performance/create-df.py ${{ env.FOLDER }} ${{ inputs.workload }} \
                ${{ inputs.script }} ${PRECISIONS[idx]} ${{ inputs.benchmark_type }} ${{ inputs.tolerance }} ${THRESHOLDS[idx]} \
                ${RESULT} PASS ${STEP_URL} ${{ inputs.output_folder }}
            elif [[ "${{ inputs.benchmark_type }}" == "latency" ]] && (( $(echo "${RESULT} >= ${UPPER_LIMIT}" | bc -l) )); then
              python ${GITHUB_WORKSPACE}/.github/actions/check-performance/create-df.py ${{ env.FOLDER }} ${{ inputs.workload }} \
                ${{ inputs.script }} ${PRECISIONS[idx]} ${{ inputs.benchmark_type }} ${{ inputs.tolerance }} ${THRESHOLDS[idx]} \
                ${RESULT} FAIL ${STEP_URL} ${{ inputs.output_folder }}
            elif [[ "${{ inputs.benchmark_type }}" == "throughput" || "${{ inputs.benchmark_type }}" == "accuracy" ]] && (( $(echo "${RESULT} > ${LOWER_LIMIT}" | bc -l) )); then
              python ${GITHUB_WORKSPACE}/.github/actions/check-performance/create-df.py ${{ env.FOLDER }} ${{ inputs.workload }} \
                ${{ inputs.script }} ${PRECISIONS[idx]} ${{ inputs.benchmark_type }} ${{ inputs.tolerance }} ${THRESHOLDS[idx]} \
                ${RESULT} PASS ${STEP_URL} ${{ inputs.output_folder }}
            elif [[ "${{ inputs.benchmark_type }}" == "throughput" || "${{ inputs.benchmark_type }}" == "accuracy" ]] && (( $(echo "${RESULT} <= ${LOWER_LIMIT}" | bc -l) )); then
              python ${GITHUB_WORKSPACE}/.github/actions/check-performance/create-df.py ${{ env.FOLDER }} ${{ inputs.workload }} \
                ${{ inputs.script }} ${PRECISIONS[idx]} ${{ inputs.benchmark_type }} ${{ inputs.tolerance }} ${THRESHOLDS[idx]} \
                ${RESULT} FAIL ${STEP_URL} ${{ inputs.output_folder }}
            fi
          fi
        done
    - uses: actions/upload-artifact@v3
      with:
        name: workload-performances
        path: tests/cicd/output/performances/*
